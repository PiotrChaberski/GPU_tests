{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vzGsmOEfd3ct"
   },
   "source": [
    "# Testing local GPU vs. Colab GPUs performance using GAN MNIST generator with PyTorch\n",
    "\n",
    "Model based on:  \n",
    "https://www.tensorflow.org/tutorials/generative/dcgan\n",
    "\n",
    "Pytorch implementation based on:  \n",
    "https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8p_DOhcKZbfL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from IPython import display\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3hLcNIqkWeQ5"
   },
   "outputs": [],
   "source": [
    "# Settings and parameters\n",
    "\n",
    "# Runtime settings\n",
    "local_runtime = False    # local runtime with CUDA on Win10\n",
    "use_gpu = True\n",
    "gdrive_mounted = False\n",
    "\n",
    "# Try to use CUDA only if available\n",
    "gpu_selected_and_available = use_gpu & torch.cuda.is_available()\n",
    "\n",
    "# Experiment parameters\n",
    "batch_size = 256\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 3\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 972
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10846,
     "status": "ok",
     "timestamp": 1584548500924,
     "user": {
      "displayName": "Piotr Chaberski",
      "photoUrl": "",
      "userId": "02798827690844129152"
     },
     "user_tz": -60
    },
    "id": "ALwRoJAfWdtt",
    "outputId": "f41b9fc8-5570-4b70-bc61-9c9a6f16aa4c"
   },
   "outputs": [],
   "source": [
    "# Print backend info\n",
    "\n",
    "print('Backend info:')\n",
    "\n",
    "if local_runtime:\n",
    "    if gpu_selected_and_available:\n",
    "        !\"C:\\\\Program Files\\\\NVIDIA Corporation\\\\NVSMI\\\\nvidia-smi.exe\"\n",
    "    else:\n",
    "        !wmic cpu get caption, deviceid, name, numberofcores, maxclockspeed, status\n",
    "else:\n",
    "    if gpu_selected_and_available:\n",
    "        !nvidia-smi\n",
    "    else:\n",
    "        !cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GfVmzWKKWCuK"
   },
   "outputs": [],
   "source": [
    "# Directory settings - restart runtime if runtime settings changed!\n",
    "\n",
    "if not local_runtime:\n",
    "    if gdrive_mounted:\n",
    "        work_dir = '/content/drive/My Drive/GPU_tests/GAN_GPU_tests'\n",
    "    else:\n",
    "        work_dir = '/content/GAN_GPU_tests'\n",
    "else:\n",
    "    work_dir = 'C://OtherProjects//GPU_tests//GAN_GPU_tests'\n",
    "os.makedirs(work_dir, exist_ok=True)\n",
    "os.chdir(work_dir)\n",
    "\n",
    "if gpu_selected_and_available:\n",
    "    if local_runtime:\n",
    "        device_name = !\"C:\\\\Program Files\\\\NVIDIA Corporation\\\\NVSMI\\\\nvidia-smi.exe\" --query-gpu=name --format=csv,noheader\n",
    "        device_name = device_name[0]\n",
    "    else:\n",
    "        device_name = !nvidia-smi --query-gpu=name --format=csv,noheader\n",
    "        device_name = device_name[0]\n",
    "else:\n",
    "    if local_runtime:\n",
    "        device_name = 'Local_CPU'\n",
    "    else:\n",
    "        device_name = 'Colab_CPU'\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), 'data')\n",
    "save_dir = os.path.join(os.getcwd(), 'results',\n",
    "                        re.sub(' ', '_', device_name) + '_' +\\\n",
    "                        re.sub('-| |:', '', str(datetime.now()).split('.')[0]))\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fmr4X54Do4Ee"
   },
   "outputs": [],
   "source": [
    "# Prepare training set\n",
    "\n",
    "trs = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_set = datasets.MNIST(root=data_path, train=True,\n",
    "                           transform=trs, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iOlIwhk2prfR"
   },
   "outputs": [],
   "source": [
    "# Prepare data loader\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ve60X5Szw-0j"
   },
   "outputs": [],
   "source": [
    "# Calcuate number of batches (iterations)\n",
    "\n",
    "num_batches = len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Flxo1GmxE3R"
   },
   "outputs": [],
   "source": [
    "# Discriminator class definition\n",
    "\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 5, stride=2, padding=2),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv2d(64, 128, 5, stride=2, padding=2),\n",
    "            nn.LeakyReLU(0.3)\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(6272, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        BS = x.shape[0]\n",
    "        x = self.conv(x)\n",
    "        x = x.view(BS, -1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39759,
     "status": "ok",
     "timestamp": 1584548529881,
     "user": {
      "displayName": "Piotr Chaberski",
      "photoUrl": "",
      "userId": "02798827690844129152"
     },
     "user_tz": -60
    },
    "id": "5pyEOBdNOOyg",
    "outputId": "043c28e6-31e0-4115-e8a6-f11ca5772fb9"
   },
   "outputs": [],
   "source": [
    "# Discriminator test\n",
    "\n",
    "discriminator = Discriminator()\n",
    "sample_tensor = torch.rand(batch_size, 1, 28, 28)\n",
    "\n",
    "if gpu_selected_and_available:\n",
    "    discriminator.cuda()\n",
    "    sample_tensor = sample_tensor.cuda()\n",
    "\n",
    "print(f'Model on CUDA: {next(discriminator.parameters()).is_cuda}\\\n",
    "        Input on CUDA: {sample_tensor.is_cuda}\\\n",
    "        Output shape: {discriminator.forward(sample_tensor).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWWmqDSfOmC9"
   },
   "outputs": [],
   "source": [
    "# Generator class definition\n",
    "\n",
    "class Generator(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(100, 7*7*256, bias=False)\n",
    "        )        \n",
    "\n",
    "        self.tconv = nn.Sequential(\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.ConvTranspose2d(256, 128, 5, stride=1,\n",
    "                               padding=2, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.ConvTranspose2d(128, 64, 5, stride=2,\n",
    "                               padding=2, output_padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.ConvTranspose2d(64, 1, 5, stride=2,\n",
    "                               padding=2, output_padding=1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        BS = x.shape[0]\n",
    "        x = self.linear(x)\n",
    "        x = x.view(BS, 256, 7, 7)\n",
    "        x = self.tconv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41093,
     "status": "ok",
     "timestamp": 1584548531233,
     "user": {
      "displayName": "Piotr Chaberski",
      "photoUrl": "",
      "userId": "02798827690844129152"
     },
     "user_tz": -60
    },
    "id": "JNh1DetrqfJ_",
    "outputId": "34323f96-1aea-43ca-8b0d-6f875001e732"
   },
   "outputs": [],
   "source": [
    "# Generator test\n",
    "\n",
    "generator = Generator()\n",
    "sample_noise = torch.rand(batch_size, 100)\n",
    "\n",
    "if gpu_selected_and_available:\n",
    "    generator.cuda()\n",
    "    sample_noise = sample_noise.cuda()\n",
    "\n",
    "generated_images = generator.forward(sample_noise)\n",
    "\n",
    "print(f'Model on CUDA: {next(generator.parameters()).is_cuda}\\\n",
    "        Input on CUDA: {sample_noise.is_cuda}\\\n",
    "        Output shape: {generated_images.shape}')\n",
    "\n",
    "if gpu_selected_and_available:\n",
    "    generated_images = generated_images.cpu()\n",
    "\n",
    "print('Sample generated image:')\n",
    "plt.imshow(generated_images[0, 0, :, :].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R_KFjVYxNi0O"
   },
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "\n",
    "def noise(size, on_cuda=False):\n",
    "    n = torch.randn(size, 100)\n",
    "    if on_cuda:\n",
    "        n = n.cuda()\n",
    "    return n\n",
    "\n",
    "def ones_target(size, on_cuda=False):\n",
    "    data = torch.ones(size, 1)\n",
    "    if on_cuda:\n",
    "        data = data.cuda()\n",
    "    return data\n",
    "\n",
    "def zeros_target(size, on_cuda=False):\n",
    "    data = torch.zeros(size, 1)\n",
    "    if on_cuda:\n",
    "        data = data.cuda()\n",
    "    return data\n",
    "\n",
    "def generate_and_save_images(save_dir, model, epoch, test_input, on_cuda=False):\n",
    "    model.train(False)\n",
    "    predictions = model.forward(test_input)\n",
    "    if on_cuda:\n",
    "        predictions = predictions.cpu()\n",
    "    predictions = predictions.detach().numpy()\n",
    "    model.train(True)\n",
    "\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(predictions[i, 0, :, :]*127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, f'image_at_epoch_{epoch}.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xZ00ff7FSW5D"
   },
   "outputs": [],
   "source": [
    "# Create discriminator and generator\n",
    "\n",
    "discriminator = Discriminator()\n",
    "generator = Generator()\n",
    "if gpu_selected_and_available:\n",
    "    discriminator.cuda()\n",
    "    generator.cuda()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fCaCw336PNKz"
   },
   "outputs": [],
   "source": [
    "# Set optimizer and loss function\n",
    "\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(),\n",
    "                                     lr=learning_rate)\n",
    "generator_optimizer = optim.Adam(generator.parameters(),\n",
    "                                 lr=learning_rate)\n",
    "loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E0IjEeMlTrm7"
   },
   "outputs": [],
   "source": [
    "# Function for discriminator training step\n",
    "\n",
    "def train_discriminator(optimizer, real_data, fake_data):\n",
    "    N = real_data.size(0)\n",
    "\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    ### Train on Real Data\n",
    "    prediction_real = discriminator(real_data)\n",
    "\n",
    "    # Calculate loss and backpropagate\n",
    "    loss_real = loss(prediction_real,\n",
    "                     ones_target(N, on_cuda=gpu_selected_and_available))\n",
    "    loss_real.backward()\n",
    "\n",
    "    ### Train on Fake Data\n",
    "    prediction_fake = discriminator(fake_data)\n",
    "    \n",
    "    # Calculate loss and backpropagate\n",
    "    loss_fake = loss(prediction_fake,\n",
    "                     zeros_target(N, on_cuda=gpu_selected_and_available))\n",
    "    loss_fake.backward()\n",
    "    \n",
    "    ### Update weights with gradients\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Return loss and predictions for real and fake inputs\n",
    "    return loss_real + loss_fake, prediction_real, prediction_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FxgBFz1mUkEY"
   },
   "outputs": [],
   "source": [
    "# Function for generator training step\n",
    "\n",
    "def train_generator(optimizer, fake_data):\n",
    "    N = fake_data.size(0)\n",
    "\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Sample noise and generate fake data\n",
    "    prediction = discriminator(fake_data)\n",
    "\n",
    "    # Calculate loss and backpropagate\n",
    "    gen_loss = loss(prediction,\n",
    "                    ones_target(N, on_cuda=gpu_selected_and_available))\n",
    "    gen_loss.backward()\n",
    "\n",
    "    # Update weights with gradients\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Return loss\n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AbwCxfx2U013"
   },
   "outputs": [],
   "source": [
    "# Generate test noise\n",
    "\n",
    "test_noise = noise(num_examples_to_generate,\n",
    "                   on_cuda=gpu_selected_and_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1584552815703,
     "user": {
      "displayName": "Piotr Chaberski",
      "photoUrl": "",
      "userId": "02798827690844129152"
     },
     "user_tz": -60
    },
    "id": "5EMsWyZhVKD2",
    "outputId": "feed7dc8-6aa4-4293-dc66-f80bea424a0e"
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "epoch_times = []\n",
    "epoch_disc_losses = []\n",
    "epoch_gen_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    t0 = time()\n",
    "    running_disc_loss = 0.0\n",
    "    running_gen_loss = 0.0\n",
    "    \n",
    "    for n_batch, (real_batch, _) in enumerate(data_loader):\n",
    "        N = real_batch.size(0)\n",
    "        if gpu_selected_and_available:\n",
    "            real_batch = real_batch.cuda()\n",
    "\n",
    "        ### Train Discriminator\n",
    "        real_data = real_batch\n",
    "        # Generate fake data and detach \n",
    "        fake_data = generator(noise(N, on_cuda=gpu_selected_and_available))\n",
    "        # Train Disctriminator\n",
    "        disc_loss, d_pred_real, d_pred_fake = \\\n",
    "              train_discriminator(discriminator_optimizer, real_data, fake_data)\n",
    "\n",
    "        ### Train Generator\n",
    "        # Generate fake data\n",
    "        fake_data = generator(noise(N, on_cuda=gpu_selected_and_available))\n",
    "        # Train Generator\n",
    "        gen_loss = train_generator(generator_optimizer, fake_data)\n",
    "        \n",
    "        # Record batch losses\n",
    "        if gpu_selected_and_available:\n",
    "            disc_loss = disc_loss.cpu()\n",
    "            gen_loss = gen_loss.cpu()\n",
    "        running_disc_loss += disc_loss.item()\n",
    "        running_gen_loss += gen_loss.item()\n",
    "\n",
    "    # Record epoch time and losses\n",
    "    epoch_times.append(time() - t0)\n",
    "    epoch_disc_loss = running_disc_loss / num_batches\n",
    "    epoch_gen_loss = running_gen_loss / num_batches\n",
    "    epoch_disc_losses.append(epoch_disc_loss)\n",
    "    epoch_gen_losses.append(epoch_gen_loss)\n",
    "\n",
    "    # Display generated images after each epoch\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(save_dir, generator, epoch + 1, test_noise,\n",
    "                             on_cuda=gpu_selected_and_available)\n",
    "\n",
    "    # Print epoch time and losses\n",
    "    print(f'Epoch: {epoch + 1}\\\n",
    "            Epoch time: {epoch_times[-1]}\\\n",
    "            Discriminator loss: {epoch_disc_loss}\\\n",
    "            Generator loss: {epoch_gen_loss}')\n",
    "    \n",
    "display.clear_output(wait=True)\n",
    "print(f'Training complete. Total time in secs: {sum(epoch_times):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1329,
     "status": "ok",
     "timestamp": 1584552817022,
     "user": {
      "displayName": "Piotr Chaberski",
      "photoUrl": "",
      "userId": "02798827690844129152"
     },
     "user_tz": -60
    },
    "id": "GYF4Wf-gxA1k",
    "outputId": "c626bd15-d601-43ea-a0e2-133a78079e5a"
   },
   "outputs": [],
   "source": [
    "# Display and save generated images after last epoch\n",
    "print('Sample of generated images after last epoch:')\n",
    "generate_and_save_images(save_dir, generator, num_epochs, test_noise,\n",
    "                         on_cuda=gpu_selected_and_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1584552817023,
     "user": {
      "displayName": "Piotr Chaberski",
      "photoUrl": "",
      "userId": "02798827690844129152"
     },
     "user_tz": -60
    },
    "id": "0C_8Z1C9xE0-",
    "outputId": "4473e2da-59a0-4f9b-861c-85d46b2ee5ca"
   },
   "outputs": [],
   "source": [
    "# Print and save time per epoch and gen/disc losses\n",
    "stats_df = pd.DataFrame({'Epoch': list(range(1, num_epochs + 1)),\n",
    "                         'Epoch_time': epoch_times,\n",
    "                         'Discriminator_loss': epoch_disc_losses,\n",
    "                         'Generator_loss': epoch_gen_losses})\n",
    "stats_df.to_csv(os.path.join(save_dir, 'stats.csv'), index=False)\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1584552817023,
     "user": {
      "displayName": "Piotr Chaberski",
      "photoUrl": "",
      "userId": "02798827690844129152"
     },
     "user_tz": -60
    },
    "id": "QbOMODzcxEm1",
    "outputId": "a9e9e08a-a01e-47a1-92fb-0dc8faee6360"
   },
   "outputs": [],
   "source": [
    "# Print and save epoch losses plot\n",
    "plt.plot(epoch_gen_losses)\n",
    "plt.plot(epoch_disc_losses)\n",
    "plt.title('Generator and discriminator losses')\n",
    "plt.legend(['gen_loss', 'disc_loss'])\n",
    "plt.savefig(os.path.join(save_dir, 'epoch_losses.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1584552817024,
     "user": {
      "displayName": "Piotr Chaberski",
      "photoUrl": "",
      "userId": "02798827690844129152"
     },
     "user_tz": -60
    },
    "id": "Gy16dup-aKZx",
    "outputId": "393394e1-becd-4265-a5e2-3029ecffc8f8"
   },
   "outputs": [],
   "source": [
    "# Print and save epoch times plot\n",
    "plt.plot(epoch_times)\n",
    "plt.title('Epoch times')\n",
    "plt.savefig(os.path.join(save_dir, 'epoch_times.png'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM9X5IQ8mlG6DMgF72EpPj4",
   "collapsed_sections": [],
   "mount_file_id": "1ZhMyHahJ5ULR1JE4GPuFYgSjqliJoFdS",
   "name": "gan_mnist_gpu_perf_test.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
